{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train.csv', index_col='Id', keep_default_na=False,\n",
    "                                                       # na_values=\n",
    "                                                        )\n",
    "test =  pd.read_csv('datasets/test.csv', index_col='Id', keep_default_na=False,\n",
    "                                                        #na_values=\n",
    "                                                        )\n",
    "\n",
    "train = pd.concat([train, test])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(train):\n",
    "    # Replace all instances of \"NA\" with \"0\" in column: 'LotFrontage'\n",
    "    train['LotFrontage'] = train['LotFrontage'].str.replace(\"NA\", \"0\", case=False, regex=False)\n",
    "    # Change column type to float64 for column: 'LotFrontage'\n",
    "    train = train.astype({'LotFrontage': 'float64'})\n",
    "    # Change column type to category for column: 'MSSubClass'\n",
    "    # train = train.astype({'MSSubClass': 'category'})\n",
    "    # Change column type to category for column: 'MSZoning'\n",
    "    # train = train.astype({'MSZoning': 'category'})\n",
    "    # Change column type to category for column: 'Street'\n",
    "    # train = train.astype({'Street': 'category'})\n",
    "    # Change column type to category for columns: 'Alley', 'LotShape' and 14 other columns\n",
    "    # train = train.astype({'Alley': 'category', 'LotShape': 'category', 'LandContour': 'category', 'Utilities': 'category', 'LotConfig': 'category', 'LandSlope': 'category', 'Neighborhood': 'category', 'Condition1': 'category', 'Condition2': 'category', 'BldgType': 'category', 'HouseStyle': 'category', 'RoofStyle': 'category', 'RoofMatl': 'category', 'Exterior1st': 'category', 'MasVnrType': 'category', 'Exterior2nd': 'category'})\n",
    "    # Replace all instances of 0 with -0.1 in column: 'LotFrontage'\n",
    "    train.loc[train['LotFrontage'] == 0, 'LotFrontage'] = np.nan\n",
    "    # Replace all instances of \"na\" with \"0\" in column: 'MasVnrArea'\n",
    "    train['MasVnrArea'] = train['MasVnrArea'].str.replace(\"na\", \"0\", case=False, regex=False)\n",
    "    # Change column type to float64 for column: 'MasVnrArea'\n",
    "    train = train.astype({'MasVnrArea': 'float64'})\n",
    "    # Change column type to category for columns: 'ExterQual', 'ExterCond' and 21 other columns\n",
    "    # train = train.astype({'ExterQual': 'category', 'ExterCond': 'category', 'Foundation': 'category', 'BsmtQual': 'category', 'BsmtCond': 'category', 'BsmtExposure': 'category', 'BsmtFinType1': 'category', 'BsmtFinType2': 'category', 'Heating': 'category', 'HeatingQC': 'category', 'CentralAir': 'category', 'Electrical': 'category', 'KitchenQual': 'category', 'Functional': 'category', 'FireplaceQu': 'category', 'GarageType': 'category', 'GarageFinish': 'category', 'GarageQual': 'category', 'GarageCond': 'category', 'PavedDrive': 'category', 'PoolQC': 'category', 'Fence': 'category', 'MiscFeature': 'category'})\n",
    "    # Change column type to category for columns: 'SaleType', 'SaleCondition'\n",
    "    # train = train.astype({'SaleType': 'category', 'SaleCondition': 'category','GarageYrBlt': 'category',\n",
    "                        #   'YearRemodAdd': 'category','YearBuilt': 'category','YrSold': 'category',\n",
    "                        #   'OverallQual': 'category','OverallCond': 'category','MoSold': 'category'})\n",
    "    return train\n",
    "\n",
    "train_clean = clean_data(train.copy())\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = clean_data(test.copy())\n",
    "test_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Description Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = pd.read_csv('datasets/data_description.txt',\n",
    "                                sep=r'[\\t:]',\n",
    "                                na_filter=False,\n",
    "                                header=None,\n",
    "                                names = ['variable','description'],\n",
    "                                # na_values= ['UNK'],\n",
    "                                on_bad_lines='skip',\n",
    "                                skip_blank_lines=False,\n",
    "                                skipinitialspace=False,\n",
    "                                # iterator=True,\n",
    "                                # chunksize=1\n",
    "                                \n",
    "\n",
    ")\n",
    "data_description.drop(axis='rows', index=373, inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = data_description.query('description.isna()').index.to_list()\n",
    "vars = []\n",
    "\n",
    "for brk in breaks:\n",
    "    vars.append(data_description.at[brk+1, 'variable'] )\n",
    "\n",
    "vars.insert(0, data_description.at[0, 'variable'])\n",
    "data_description.insert(1, 'category', 'see')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "x=0\n",
    "for brk in breaks:\n",
    "    data_description.loc[i: brk, 'category'] = vars[x]\n",
    "    i=breaks[x]+1\n",
    "    x+=1\n",
    "    if brk==462:\n",
    "        data_description.loc[brk:, 'category'] = vars[x]\n",
    "        break\n",
    "\n",
    "data_description.loc[data_description['category'] == \"see\", 'category'] = \"SaleCondition\"\n",
    "\n",
    "data_description.drop(breaks, axis=0, inplace=True)\n",
    "data_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = data_description.query('variable == category').index\n",
    "data_description.drop(desc, inplace=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = list(data_description.query(\"variable.str.strip() == 'NA' \").category.values)\n",
    "na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_na= list(set(train_clean.columns.to_list()).difference(set(na)))\n",
    "n_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Set Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in n_na:\n",
    "    if train_clean[col].eq('NA').sum() > 0:\n",
    "        print(col)\n",
    "        train_clean.loc[train_clean[col] == 'NA', col] = None\n",
    "    # else:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(df=train_clean):\n",
    "    missing = df.isna().sum()\n",
    "    missing_data = missing[missing > 0]\n",
    "    return missing_data\n",
    "\n",
    "check_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(train_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_clean[[\"GarageYrBlt\", \"YearBuilt\"]].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean[\"GarageYrBlt\"].fillna(train_clean[\"YearBuilt\"],inplace=True)\n",
    "test_clean[\"GarageYrBlt\"].fillna(test_clean[\"YearBuilt\"],inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=train_clean, x='LotFrontage',kind='strip', row='LotConfig', sharex=False,height=3,orient='portrait')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_front_dic = train_clean.mask(train_clean.LotFrontage.isna()) \\\n",
    "            .groupby('LotConfig') \\\n",
    "                ['LotFrontage'].median().round() \\\n",
    "                .to_dict()\n",
    "\n",
    "lot_front_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_LF = train_clean[(train_clean.LotConfig == key) & (train_clean.LotFrontage.isna())]  \n",
    "\n",
    "for key, item in lot_front_dic.items():\n",
    "    train_clean.loc[(train_clean.LotConfig==key ) & (train_clean.LotFrontage.isna()), 'LotFrontage'] = item\n",
    "    test_clean.loc[(test_clean.LotConfig==key ) & (test_clean.LotFrontage.isna()), 'LotFrontage'] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.MasVnrType.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.Electrical.fillna(method='pad', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing(train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Numeric Strings to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_clean.select_dtypes('object').columns:\n",
    "    if train_clean[col].str.isnumeric().sum() > 10:\n",
    "        print(col)\n",
    "        train_clean[col] = train_clean[col].astype('float64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns Dominated by a certain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbalanced_cols = []\n",
    "# for col in train_clean.select_dtypes('object').columns:\n",
    "#     value_counts = train_clean[col].value_counts(normalize=True)\n",
    "\n",
    "#     max = value_counts.max()\n",
    "    \n",
    "#     print(value_counts)\n",
    "#    # print(max)\n",
    "\n",
    "#     if max > .70:\n",
    "#         unbalanced_cols.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_clean.drop(unbalanced_cols, axis='columns',inplace=True)\n",
    "# check_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.SalePrice.fillna(0, inplace=True)\n",
    "train_clean.dropna(axis=0,inplace=True)\n",
    "print(train_clean.shape)\n",
    "check_missing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of Predictors with Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_correlation_heatmap(target_col: str or None):\n",
    "\n",
    "#     corr_data: pd.DataFrame\n",
    "    \n",
    "#     if target_col is None:\n",
    "corr_price = train_clean.corr(method='pearson', numeric_only=True)['SalePrice'].sort_values(ascending=False)\n",
    "#     elif isinstance(target_col, str):\n",
    "#         corr_data = train_clean.corr(method='pearson')\n",
    "\n",
    "sns.heatmap(corr_price.to_frame())\n",
    "plt.show()\n",
    "\n",
    "# plot_correlation_heatmap('SalePrice')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between Predictor Variables (Multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = train_clean.corr(method='pearson', numeric_only=True).sort_values(by='SalePrice')\n",
    "fig = plt.figure(figsize=(10,12))\n",
    "sns.heatmap(corr_df,cmap='BrBG', figure=fig )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop highly correlated independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrTol = 0.65\n",
    "\n",
    "# for col in corr_df:\n",
    "#     if col in corr_df.keys():\n",
    "#         thisCol = []\n",
    "#         thisVars = []\n",
    "\n",
    "#         for i in range(len(corr_df)):\n",
    "#             if abs(corr_df[col][i]) == 1.0 and col != corr_df.keys()[i]:\n",
    "#                 thisCorr = 0\n",
    "#             else:\n",
    "#                 thisCorr = ( 1 if abs(corr_df[col][i]) > corrTol else -1)\n",
    "            \n",
    "#             thisCol.append(thisCorr)\n",
    "#             thisVars.append(corr_df.keys()[i])\n",
    "        \n",
    "#         mask = np.ones(len(thisCol), dtype=bool)\n",
    "\n",
    "#         ctDelCol = 0\n",
    "\n",
    "#         for n, j in enumerate(thisCol):\n",
    "#             # is the correlation greater than 0not equal to the max corr and greater than ze\n",
    "#             mask[n] = not (j != max(thisCol) and j>=0)\n",
    "\n",
    "#             if j != max(thisCol) and j >= 0:\n",
    "#                 corr_df.pop('%s' %thisVars[n])\n",
    "#                 train_clean.pop('%s' %thisVars[n])\n",
    "#                 ctDelCol += 1\n",
    "\n",
    "#         corr_df = corr_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_del = []\n",
    "# tol = .65\n",
    "\n",
    "# for col, row in corr_df.iterrows():\n",
    "#     # print(col)\n",
    "#     # print(row)\n",
    "#     # print(f\"Current column {col}\")\n",
    "#     for col2, corr in row.items():\n",
    "#         # print(f\"Checking correlation with {col2}\")\n",
    "#         if abs(corr) > tol and col2 != col:\n",
    "#             # print(f\"Correlation of {corr} is greater than the tolerance of {tol}\")\n",
    "#             # print(\"Adding it to deleted columns\")\n",
    "#             corr_target = corr_df.loc[col, 'SalePrice']\n",
    "#             corr_target2 = corr_df.loc[col2, 'SalePrice']\n",
    "#             if corr_target > corr_target2:\n",
    "#                 cols_del.append(col2)\n",
    "#             else:\n",
    "#                 cols_del.append(col)\n",
    "\n",
    "# cols_del = list(set(cols_del))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_clean.drop(columns=cols_del, inplace=True)\n",
    "# corr_df.drop(columns=cols_del, inplace=True)\n",
    "# train_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pingouin\n",
    "# cats = train_clean.select_dtypes('object').columns.to_list()\n",
    "\n",
    "# frames = []\n",
    "# for col in range(len(cats)):\n",
    "#     frame = pingouin.welch_anova(data=train_clean, dv='SalePrice', between=cats[col]).round(3)\n",
    "#     frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = pd.concat(frames)\n",
    "# c.loc[c[\"p-unc\"] > 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = []\n",
    "# for col in range(len(cats)):\n",
    "#     frame = pingouin.normality(data=train_clean, dv='SalePrice', group=cats[col]).round(3)\n",
    "#     frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = pd.concat(frames)\n",
    "# norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import f_classif\n",
    "\n",
    "\n",
    "\n",
    "# for col in cats:\n",
    "    \n",
    "# X_new = SelectKBest(f_classif, k=15).fit_transform(train_X, train_y)\n",
    "# X_new.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize, Convert to Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ordinal = ['LotShape','LandSlope', 'ExterQual','ExterCond','BsmtQual','BsmtCond',\n",
    "            'BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC',\n",
    "            'KitchenQual','Functional','FireplaceQu','GarageFinish',\n",
    "            'GarageQual','GarageCond','PavedDrive','PoolQC',\n",
    "            'Fence']\n",
    "\n",
    "special = ['OverallCond','OverallQual','MSSubClass']\n",
    "\n",
    "time_col = ['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt','MoSold']\n",
    "\n",
    "floats = [col for col in train_clean.select_dtypes('number').columns.to_list()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binarize(train_clean):\n",
    "    \n",
    "    for col in train_clean.columns:\n",
    "        if col not in ordinal and col not in time_col and col not in floats and col not in special:\n",
    "            train_clean = pd.get_dummies(train_clean, columns=[col], drop_first=True)\n",
    "    return train_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_clean = binarize(train_clean)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ordinal = time_col + ordinal\n",
    "set(all_ordinal).difference(set(ordinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = dict ()\n",
    "\n",
    "for col in all_ordinal:\n",
    "    x = data_description.loc[data_description['category']== col, 'variable'].to_list()\n",
    "    order[col] = x\n",
    "\n",
    "print(order)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_ordinals(df):\n",
    "\n",
    "    for col, categories in order.items():\n",
    "        n = len(col)\n",
    "        codes = np.zeros(n)\n",
    "        if len(categories) != 0:\n",
    "            # df[col], _ = pd.Categorical(df[col])\n",
    "            df[col] = pd.Categorical(df[col], categories=categories, ordered=True)\n",
    "            df[col] = df[col].cat.codes\n",
    "        # else:\n",
    "    return df \n",
    "\n",
    "train_clean = factorize_ordinals(train_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = binarize(test_clean)\n",
    "test_clean = factorize_ordinals(test_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import r_regression, f_regression, mutual_info_regression, SelectKBest, RFECV\n",
    "import xgboost\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_clean.loc[train_clean['SalePrice'] != 0].drop(columns='SalePrice')\n",
    "y_train = train_clean.loc[train_clean['SalePrice'] != 0, 'SalePrice'] \n",
    "X_test = train_clean.loc[train_clean['SalePrice'] == 0].drop(columns='SalePrice')\n",
    "# y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.to_csv('datasets/train_clean.csv')\n",
    "test_clean.to_csv('datasets/test_clean.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Linear Regression)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit (y_pred):\n",
    "    i = pd.Index(name='Id', data= range(len(y_pred)))\n",
    "    s = pd.Series(data=y_pred, dtype='float64', index=i, name='SalePrice')\n",
    "\n",
    "    return s.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = submit(y_pred)\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(criterion='squared_error')\n",
    "\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test)\n",
    "b= submit(y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfr = rfr.predict(X_test)\n",
    "\n",
    "c = submit(y_pred_rfr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_submissions (frames: list[pd.DataFrame], models):\n",
    "\n",
    "    keys = [model.__class__.__name__ for model in models ]\n",
    "\n",
    "    # try:\n",
    "    return pd.concat(frames, axis=1, join='inner', keys=keys)\n",
    "    # except Exception:\n",
    "        \n",
    "        # print(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(tests, k, X_train, y_train):\n",
    "    dfs = []\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    for test in tests:\n",
    "        best = SelectKBest(test, k=k).fit(X_train, y_train)\n",
    "\n",
    "        scores = sorted(best.scores_, reverse=True)[:10]\n",
    "\n",
    "        # scores = scaler.fit_transform(np.array(scores).reshape(-1, 1)).reshape(10)\n",
    "\n",
    "        df = pd.DataFrame({'variable': best.get_feature_names_out(),\n",
    "                'score':scores} )\n",
    "        \n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [r_regression, f_regression, mutual_info_regression]\n",
    "k=10\n",
    "best = get_best(tests, k, X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.variable.value_counts(ascending=False).index[:10].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=5, n_estimators=10, learning_rate=1.0)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dbrt = gbrt.predict(X_test)\n",
    "d = submit(y_pred_dbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = submit(y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = submit(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_submissions([a,b,c,d,e,f], models=[linear_reg,dt,rfr,gbrt,ada,xgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ccecdc02aa416300a64487fe6971a8398ebaf053d2b2768f769ac21dbbf13f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
